{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A test for applying BERT to cloze task\n",
    "\n",
    "According to the answer from github [How can I apply Bert to a cloze task](https://github.com/huggingface/transformers/issues/80#issuecomment-444445782)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most likely word is \"enjoy\".\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text = 'From Monday to Friday most people are busy working or studying, '\\\n",
    "       'but in the evenings and weekends they are free and _ themselves.'\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "masked_index = tokenized_text.index('_')\n",
    "tokenized_text[masked_index] = '[PAD]'\n",
    "\n",
    "candidates = ['love', 'work', 'enjoy', 'play']\n",
    "candidates_ids = tokenizer.convert_tokens_to_ids(candidates)\n",
    "\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "segments_ids = [0] * len(tokenized_text)\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "language_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "language_model.eval()\n",
    "\n",
    "predictions = language_model(tokens_tensor, segments_tensors)\n",
    "predictions_candidates = predictions[0, masked_index, candidates_ids]\n",
    "answer_idx = torch.argmax(predictions_candidates).item()\n",
    "\n",
    "print(f'The most likely word is \"{candidates[answer_idx]}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment of applying AUM to Bert based method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertForSequenceClassification\n",
    "from pytorch_pretrained_bert import BertConfig, BertAdam\n",
    "# import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "\n",
    "\n",
    "class MultiNLIDataset(Dataset):\n",
    "    def __init__(self,root='/media/felicia/Data/multinli',matched=True,tokenized=True,max_length=12):\n",
    "        super(MultiNLIDataset,self).__init__()\n",
    "        self.root=root\n",
    "        self.matched=matched\n",
    "        self.tokenized=tokenized\n",
    "        self.max_length=max_length\n",
    "        self.jsonfile=\"multinli_1.0_dev_matched.jsonl\" if self.matched else \"multinli_1.0_dev_mismatched.jsonl\"\n",
    "        self.filename=os.path.join(self.root,self.jsonfile)\n",
    "\n",
    "\n",
    "        self.num_labels = 2\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.LABEL_MAP = {\n",
    "                \"entailment\": 0,\n",
    "                \"neutral\": 1,\n",
    "                \"contradiction\": 2,\n",
    "                \"hidden\": 0\n",
    "            }\n",
    "\n",
    "        self.data=[]\n",
    "        self.sentences=[]\n",
    "        self.labels=[]\n",
    "        self.load_data()\n",
    "        self.random_flip = torch.randint(9815, (200, ))\n",
    "#         self.random_flip = torch.randint(800, (20, ))\n",
    "        self.random_shift = dict()\n",
    "        for flip_index in self.random_flip:\n",
    "            self.random_shift[str(int(flip_index))] = int(2*(torch.rand(1)>0.5)-1)\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.filename) as f:\n",
    "            for idx, line in enumerate(f):\n",
    "#                 if idx > 800:\n",
    "#                     continue\n",
    "                example=json.loads(line) # dict\n",
    "                self.data.append(example)\n",
    "        if self.tokenized:\n",
    "            self.tokenize()\n",
    "\n",
    "    \n",
    "    def tokenize(self):\n",
    "        for i, text in enumerate(self.data):\n",
    "            sent=text[\"sentence1\"]\n",
    "            label=text[\"gold_label\"]\n",
    "            if label not in self.LABEL_MAP:\n",
    "                continue\n",
    "\n",
    "            tokenized_text = self.tokenizer.tokenize(sent)\n",
    "            indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "            if len(indexed_tokens)<self.max_length:\n",
    "                indexed_tokens+=[0]*(self.max_length-len(indexed_tokens))\n",
    "            else:\n",
    "                indexed_tokens=indexed_tokens[:self.max_length]\n",
    "            indexed_tokens=np.array(indexed_tokens)\n",
    "\n",
    "            self.sentences.append(indexed_tokens)\n",
    "            self.labels.append(self.LABEL_MAP[label])\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sent = self.sentences[index]\n",
    "        if index in self.random_flip:\n",
    "            label = self.labels[index]+self.random_shift[str(index)]\n",
    "            if label>2:\n",
    "                label = 0\n",
    "            elif label<0:\n",
    "                label = 2\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "\n",
    "        return index,sent,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "#         return 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "# def Trainer(batch_size=4, epoch = 50, n_classes = 3, vocab_size = 30522):\n",
    "batch_size=24\n",
    "epoch = 50\n",
    "n_classes = 3\n",
    "vocab_size = 30522\n",
    "writer = SummaryWriter('runs/NLP_AUM_First')\n",
    "\n",
    "config = BertConfig(vocab_size)\n",
    "model = BertForSequenceClassification(config, n_classes)\n",
    "model.to(\"cuda\")\n",
    "dataset = MultiNLIDataset(\"./multinli_1.0\", max_length=217)\n",
    "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle=True)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = BertAdam(model.parameters(), lr = 0.001)\n",
    "aum = torch.zeros([epoch, len(dataset), n_classes]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "Epoch 0, Iter 99:1.6757709389925004\n",
      "Epoch 0, Iter 199:1.2281666904687882\n",
      "Epoch 0, Iter 299:1.2215930885076522\n",
      "Epoch 0, Iter 399:1.2773745220899582\n",
      "Epoch 1:\n",
      "Epoch 1, Iter 99:1.1661991101503373\n",
      "Epoch 1, Iter 199:1.1588362067937852\n",
      "Epoch 1, Iter 299:1.1836058419942856\n",
      "Epoch 1, Iter 399:1.202410506606102\n",
      "Epoch 2:\n",
      "Epoch 2, Iter 99:1.1534832501411438\n",
      "Epoch 2, Iter 199:1.1706461936235428\n",
      "Epoch 2, Iter 299:1.2237022691965103\n",
      "Epoch 2, Iter 399:1.160482205748558\n",
      "Epoch 3:\n",
      "Epoch 3, Iter 99:1.1634809613227843\n",
      "Epoch 3, Iter 199:1.1863568758964538\n",
      "Epoch 3, Iter 299:1.1532067954540253\n",
      "Epoch 3, Iter 399:1.147111548781395\n",
      "Epoch 4:\n",
      "Epoch 4, Iter 99:1.1855076175928116\n",
      "Epoch 4, Iter 199:1.1554437613487243\n",
      "Epoch 4, Iter 299:1.150177595615387\n",
      "Epoch 4, Iter 399:1.1651782935857773\n",
      "Epoch 5:\n",
      "Epoch 5, Iter 99:1.158514493703842\n",
      "Epoch 5, Iter 199:1.1576241284608841\n",
      "Epoch 5, Iter 299:1.1568636012077331\n",
      "Epoch 5, Iter 399:1.1802125948667526\n",
      "Epoch 6:\n",
      "Epoch 6, Iter 99:1.132398248910904\n",
      "Epoch 6, Iter 199:1.1445320463180542\n",
      "Epoch 6, Iter 299:1.1508914917707442\n",
      "Epoch 6, Iter 399:1.1540329676866532\n",
      "Epoch 7:\n",
      "Epoch 7, Iter 99:1.150559977889061\n",
      "Epoch 7, Iter 199:1.1767007029056549\n",
      "Epoch 7, Iter 299:1.1601147449016571\n",
      "Epoch 7, Iter 399:1.1676501333713531\n",
      "Epoch 8:\n",
      "Epoch 8, Iter 99:1.144605166912079\n",
      "Epoch 8, Iter 199:1.1538113570213318\n",
      "Epoch 8, Iter 299:1.1685954093933106\n",
      "Epoch 8, Iter 399:1.1729258185625075\n",
      "Epoch 9:\n",
      "Epoch 9, Iter 99:1.144496330022812\n",
      "Epoch 9, Iter 199:1.1363126313686371\n",
      "Epoch 9, Iter 299:1.1800372463464737\n",
      "Epoch 9, Iter 399:1.155218967795372\n",
      "Epoch 10:\n",
      "Epoch 10, Iter 99:1.1642044311761857\n",
      "Epoch 10, Iter 199:1.146405119895935\n",
      "Epoch 10, Iter 299:1.1515313720703124\n",
      "Epoch 10, Iter 399:1.1613874381780624\n",
      "Epoch 11:\n",
      "Epoch 11, Iter 99:1.1936091697216034\n",
      "Epoch 11, Iter 199:1.1513357430696487\n",
      "Epoch 11, Iter 299:1.1555305260419846\n",
      "Epoch 11, Iter 399:1.13651282787323\n",
      "Epoch 12:\n",
      "Epoch 12, Iter 99:1.1422207748889923\n",
      "Epoch 12, Iter 199:1.1435512912273407\n",
      "Epoch 12, Iter 299:1.1409919095039367\n",
      "Epoch 12, Iter 399:1.1458787071704863\n",
      "Epoch 13:\n",
      "Epoch 13, Iter 99:1.1325698244571685\n",
      "Epoch 13, Iter 199:1.146136185526848\n",
      "Epoch 13, Iter 299:1.147702338695526\n",
      "Epoch 13, Iter 399:1.1520171642303467\n",
      "Epoch 14:\n",
      "Epoch 14, Iter 99:1.1520166409015655\n",
      "Epoch 14, Iter 199:1.1335185194015502\n",
      "Epoch 14, Iter 299:1.1434645676612853\n",
      "Epoch 14, Iter 399:1.1412395530939101\n",
      "Epoch 15:\n",
      "Epoch 15, Iter 99:1.1571303015947343\n",
      "Epoch 15, Iter 199:1.1332244634628297\n",
      "Epoch 15, Iter 299:1.1630982542037964\n",
      "Epoch 15, Iter 399:1.1502728128433228\n",
      "Epoch 16:\n",
      "Epoch 16, Iter 99:1.1806209033727646\n",
      "Epoch 16, Iter 199:1.1803139162063598\n",
      "Epoch 16, Iter 299:1.1772587221860886\n",
      "Epoch 16, Iter 399:1.145396797657013\n",
      "Epoch 17:\n",
      "Epoch 17, Iter 99:1.1640743046998978\n",
      "Epoch 17, Iter 199:1.1531639671325684\n",
      "Epoch 17, Iter 299:1.1719330418109895\n",
      "Epoch 17, Iter 399:1.1565017652511598\n",
      "Epoch 18:\n",
      "Epoch 18, Iter 99:1.1590682899951934\n",
      "Epoch 18, Iter 199:1.155658797621727\n",
      "Epoch 18, Iter 299:1.1470605421066284\n",
      "Epoch 18, Iter 399:1.1674841052293778\n",
      "Epoch 19:\n",
      "Epoch 19, Iter 99:1.1634594148397446\n",
      "Epoch 19, Iter 199:1.147772222161293\n",
      "Epoch 19, Iter 299:1.1720314013957978\n",
      "Epoch 19, Iter 399:1.1485126829147339\n",
      "Epoch 20:\n",
      "Epoch 20, Iter 99:1.1373399126529693\n",
      "Epoch 20, Iter 199:1.1494987404346466\n",
      "Epoch 20, Iter 299:1.151963106393814\n",
      "Epoch 20, Iter 399:1.145134778022766\n",
      "Epoch 21:\n",
      "Epoch 21, Iter 99:1.133663055896759\n",
      "Epoch 21, Iter 199:1.1450739699602126\n",
      "Epoch 21, Iter 299:1.1631197512149811\n",
      "Epoch 21, Iter 399:1.1327070116996765\n",
      "Epoch 22:\n",
      "Epoch 22, Iter 99:1.1362987911701203\n",
      "Epoch 22, Iter 199:1.140383797287941\n",
      "Epoch 22, Iter 299:1.1535672116279603\n",
      "Epoch 22, Iter 399:1.1575725734233857\n",
      "Epoch 23:\n",
      "Epoch 23, Iter 99:1.1580928289890289\n",
      "Epoch 23, Iter 199:1.1466529870033264\n",
      "Epoch 23, Iter 299:1.1402311050891876\n",
      "Epoch 23, Iter 399:1.1542137211561203\n",
      "Epoch 24:\n",
      "Epoch 24, Iter 99:1.1949183803796768\n",
      "Epoch 24, Iter 199:1.1577421456575394\n",
      "Epoch 24, Iter 299:1.1489667534828185\n",
      "Epoch 24, Iter 399:1.1525032365322112\n",
      "Epoch 25:\n",
      "Epoch 25, Iter 99:1.1891480547189712\n",
      "Epoch 25, Iter 199:1.1384160101413727\n",
      "Epoch 25, Iter 299:1.159250529408455\n",
      "Epoch 25, Iter 399:1.1506825685501099\n",
      "Epoch 26:\n",
      "Epoch 26, Iter 99:1.145468612909317\n",
      "Epoch 26, Iter 199:1.1431464105844498\n",
      "Epoch 26, Iter 299:1.1401079577207565\n",
      "Epoch 26, Iter 399:1.157135056257248\n",
      "Epoch 27:\n",
      "Epoch 27, Iter 99:1.142824999690056\n",
      "Epoch 27, Iter 199:1.169870918393135\n",
      "Epoch 27, Iter 299:1.1518225026130677\n",
      "Epoch 27, Iter 399:1.1495151406526565\n",
      "Epoch 28:\n",
      "Epoch 28, Iter 99:1.1488995462656022\n",
      "Epoch 28, Iter 199:1.1461488068103791\n",
      "Epoch 28, Iter 299:1.2024745672941208\n",
      "Epoch 28, Iter 399:1.1536960864067078\n",
      "Epoch 29:\n",
      "Epoch 29, Iter 99:1.1846743470430374\n",
      "Epoch 29, Iter 199:1.1631107974052428\n",
      "Epoch 29, Iter 299:1.1389550733566285\n",
      "Epoch 29, Iter 399:1.146428911089897\n",
      "Epoch 30:\n",
      "Epoch 30, Iter 99:1.1536497020721435\n",
      "Epoch 30, Iter 199:1.1566692209243774\n",
      "Epoch 30, Iter 299:1.1603624308109284\n",
      "Epoch 30, Iter 399:1.145285152196884\n",
      "Epoch 31:\n",
      "Epoch 31, Iter 99:1.1597639083862306\n",
      "Epoch 31, Iter 199:1.1774319225549699\n",
      "Epoch 31, Iter 299:1.1569337248802185\n",
      "Epoch 31, Iter 399:1.1372186958789825\n",
      "Epoch 32:\n",
      "Epoch 32, Iter 99:1.1738074111938477\n",
      "Epoch 32, Iter 199:1.1643071264028548\n",
      "Epoch 32, Iter 299:1.155599598288536\n",
      "Epoch 32, Iter 399:1.168918824195862\n",
      "Epoch 33:\n",
      "Epoch 33, Iter 99:1.1500611227750779\n",
      "Epoch 33, Iter 199:1.1588387894630432\n",
      "Epoch 33, Iter 299:1.163074944615364\n",
      "Epoch 33, Iter 399:1.1656768703460694\n",
      "Epoch 34:\n",
      "Epoch 34, Iter 99:1.1534510713815689\n",
      "Epoch 34, Iter 199:1.1360747826099395\n",
      "Epoch 34, Iter 299:1.1694485193490982\n",
      "Epoch 34, Iter 399:1.1417698019742966\n",
      "Epoch 35:\n",
      "Epoch 35, Iter 99:1.1396308207511903\n",
      "Epoch 35, Iter 199:1.1544916117191315\n",
      "Epoch 35, Iter 299:1.1261397534608841\n",
      "Epoch 35, Iter 399:1.1398713755607606\n",
      "Epoch 36:\n",
      "Epoch 36, Iter 99:1.1903519821166992\n",
      "Epoch 36, Iter 199:1.1942336028814315\n",
      "Epoch 36, Iter 299:1.1657869696617127\n",
      "Epoch 36, Iter 399:1.1441649860143661\n",
      "Epoch 37:\n",
      "Epoch 37, Iter 99:1.1522654330730437\n",
      "Epoch 37, Iter 199:1.1482592701911927\n",
      "Epoch 37, Iter 299:1.1498655039072037\n",
      "Epoch 37, Iter 399:1.1467710679769516\n",
      "Epoch 38:\n",
      "Epoch 38, Iter 99:1.1580021899938584\n",
      "Epoch 38, Iter 199:1.1530382961034775\n",
      "Epoch 38, Iter 299:1.1492549800872802\n",
      "Epoch 38, Iter 399:1.1466241961717605\n",
      "Epoch 39:\n",
      "Epoch 39, Iter 99:1.1465024113655091\n",
      "Epoch 39, Iter 199:1.1570753419399262\n",
      "Epoch 39, Iter 299:1.1520512062311172\n",
      "Epoch 39, Iter 399:1.1617183750867843\n",
      "Epoch 40:\n",
      "Epoch 40, Iter 99:1.1522403800487517\n",
      "Epoch 40, Iter 199:1.1389987468719482\n",
      "Epoch 40, Iter 299:1.1431410896778107\n",
      "Epoch 40, Iter 399:1.1500088542699813\n",
      "Epoch 41:\n",
      "Epoch 41, Iter 99:1.15757428586483\n",
      "Epoch 41, Iter 199:1.1294645923376083\n",
      "Epoch 41, Iter 299:1.1386203479766845\n",
      "Epoch 41, Iter 399:1.1442031997442246\n",
      "Epoch 42:\n",
      "Epoch 42, Iter 99:1.1653765726089478\n",
      "Epoch 42, Iter 199:1.1475409275293351\n",
      "Epoch 42, Iter 299:1.1553748947381974\n",
      "Epoch 42, Iter 399:1.1586845856904984\n",
      "Epoch 43:\n",
      "Epoch 43, Iter 99:1.139659547805786\n",
      "Epoch 43, Iter 199:1.1525390058755876\n",
      "Epoch 43, Iter 299:1.137485418319702\n",
      "Epoch 43, Iter 399:1.1652515482902528\n",
      "Epoch 44:\n",
      "Epoch 44, Iter 99:1.1551314449310304\n",
      "Epoch 44, Iter 199:1.1538431996107101\n",
      "Epoch 44, Iter 299:1.148256061077118\n",
      "Epoch 44, Iter 399:1.165066722035408\n",
      "Epoch 45:\n",
      "Epoch 45, Iter 99:1.1344362795352936\n",
      "Epoch 45, Iter 199:1.1989280140399934\n",
      "Epoch 45, Iter 299:1.153587099313736\n",
      "Epoch 45, Iter 399:1.131464855670929\n",
      "Epoch 46:\n",
      "Epoch 46, Iter 99:1.1448013031482696\n",
      "Epoch 46, Iter 199:1.1448840689659119\n",
      "Epoch 46, Iter 299:1.139235817193985\n",
      "Epoch 46, Iter 399:1.1472952854633331\n",
      "Epoch 47:\n",
      "Epoch 47, Iter 99:1.1505344516038896\n",
      "Epoch 47, Iter 199:1.1401388657093048\n",
      "Epoch 47, Iter 299:1.1518902987241746\n",
      "Epoch 47, Iter 399:1.1465478289127349\n",
      "Epoch 48:\n",
      "Epoch 48, Iter 99:1.1711311483383178\n",
      "Epoch 48, Iter 199:1.1523963153362273\n",
      "Epoch 48, Iter 299:1.1367959833145143\n",
      "Epoch 48, Iter 399:1.1536642301082611\n",
      "Epoch 49:\n",
      "Epoch 49, Iter 99:1.1551193475723267\n",
      "Epoch 49, Iter 199:1.150814123749733\n",
      "Epoch 49, Iter 299:1.1533448004722595\n",
      "Epoch 49, Iter 399:1.150668209195137\n"
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    print(\"Epoch {}:\".format(e))\n",
    "    logits_store = torch.zeros([len(dataset), n_classes]).cuda()\n",
    "    running_loss = 0.0\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        sample_idx, text_in, labels = batch\n",
    "        logits = model(text_in.cuda())\n",
    "\n",
    "        logits_store[sample_idx] = logits\n",
    "\n",
    "        loss = criterion(logits, labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        if idx % 100 == 99:\n",
    "            print(\"Epoch {0}, Iter {1}:{2}\".format(e, idx, running_loss/100))\n",
    "            running_loss = 0.0\n",
    "    logits_topk, logits_topk_ind = torch.topk(logits_store, 2, 1)\n",
    "    aum[e] = logits_store - logits_topk[:, 0][:, None]\n",
    "    aum[e, range(aum.shape[1]), logits_topk_ind[:,0]] = logits_store[range(aum.shape[1]), logits_topk_ind[:, 0]] - logits_topk[:,1]\n",
    "#     aum[e, logits_topk_ind[0,1], 1] = logits_store[logits_topk_ind[0,1], 1] - logits_topk[1, 1]\n",
    "\n",
    "    attention_index = dataset.random_flip#Need the attention index to point out the flipped sample\n",
    "\n",
    "    for ind in attention_index:\n",
    "        writer.add_scalar(\"Sentence {}\".format(ind), aum[e, ind, dataset[int(ind)][2]], e)\n",
    "    torch.save({\"aum\": aum, \"flipped_sample\":dataset.random_flip, \"shift_label\":dataset.random_shift}, \"AUM_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "result_dict = torch.load(\"AUM.pth\")\n",
    "aum = result_dict[\"aum\"]\n",
    "flipped_sample = result_dict[\"flipped_sample\"]\n",
    "shift_label = result_dict[\"shift_label\"]\n",
    "correct = []\n",
    "mislabel = []\n",
    "for sample_idx in range(len(dataset)):\n",
    "    label = dataset.labels[sample_idx]\n",
    "    if sample_idx not in flipped_sample:\n",
    "        correct.append(aum[:1, sample_idx, label].mean().detach().cpu().numpy().item())\n",
    "    else:\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "#         shift_order = torch.where(flipped_sample==sample_idx)[0].item()\n",
    "        label += shift_label[str(sample_idx)]\n",
    "        if label > 2:\n",
    "            label = 0\n",
    "        elif label < 0:\n",
    "            label = 2\n",
    "        mislabel.append(aum[:1, sample_idx, dataset[sample_idx][2]].mean().detach().cpu().numpy().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(correct, bins=100, density=True)\n",
    "_ = plt.hist(mislabel, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected device cpu but got device cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ca7256af5c7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_store\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogits_topk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_topk_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_store\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_topk_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogits_topk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: expected device cpu but got device cuda:0"
     ]
    }
   ],
   "source": [
    "aum = torch.zeros([epoch, len(dataset), n_classes])\n",
    "aum[e] = logits_store - logits_topk[:, 0][:, None]\n",
    "aum[e, range(aum.shape[1]), logits_topk_ind[:,0]] = logits_store[range(aum.shape[1]), logits_topk_ind[0,0]] - logits_topk[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9815"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f11c2f5b9b19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-5f750c9edfff>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_flip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shift\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "aum[e, ind, dataset[ind][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b3fdbd10343a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_store\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogits_topk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_topk_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_store\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_topk_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogits_topk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "aum = torch.zeros([epoch, len(dataset), n_classes])\n",
    "aum[e]=logits_store - logits_topk[0][None]\n",
    "aum[e, range(aum.shape[1]), logits_topk_ind[:,0]] = logits_store[range(aum.shape[1]), logits_topk_ind[0,0]] - logits_topk[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-25db62aa59b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mlogits_store\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogits_topk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# - logits_topk[1, 0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "(logits_store - logits_topk[0][None]).shape\n",
    "# - logits_topk[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"./multinli_1.0/multinli_1.0_train.jsonl\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        if idx>10:\n",
    "            continue\n",
    "        print(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointmask",
   "language": "python",
   "name": "pointmask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
