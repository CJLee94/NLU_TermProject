{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "olympic-framing",
   "metadata": {},
   "source": [
    "## A test for applying BERT to cloze task\n",
    "\n",
    "According to the answer from github [How can I apply Bert to a cloze task](https://github.com/huggingface/transformers/issues/80#issuecomment-444445782)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "blessed-boutique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most likely word is \"enjoy\".\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text = 'From Monday to Friday most people are busy working or studying, '\\\n",
    "       'but in the evenings and weekends they are free and _ themselves.'\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "masked_index = tokenized_text.index('_')\n",
    "tokenized_text[masked_index] = '[PAD]'\n",
    "\n",
    "candidates = ['love', 'work', 'enjoy', 'play']\n",
    "candidates_ids = tokenizer.convert_tokens_to_ids(candidates)\n",
    "\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "segments_ids = [0] * len(tokenized_text)\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "language_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "language_model.eval()\n",
    "\n",
    "predictions = language_model(tokens_tensor, segments_tensors)\n",
    "predictions_candidates = predictions[0, masked_index, candidates_ids]\n",
    "answer_idx = torch.argmax(predictions_candidates).item()\n",
    "\n",
    "print(f'The most likely word is \"{candidates[answer_idx]}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-plaintiff",
   "metadata": {},
   "source": [
    "## Experiment of applying AUM to Bert based method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tender-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertForSequenceClassification\n",
    "from pytorch_pretrained_bert import BertConfig, BertAdam\n",
    "# import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fitting-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "\n",
    "\n",
    "class MultiNLIDataset(Dataset):\n",
    "    def __init__(self,root='/media/felicia/Data/multinli',matched=True,tokenized=True,max_length=12):\n",
    "        super(MultiNLIDataset,self).__init__()\n",
    "        self.root=root\n",
    "        self.matched=matched\n",
    "        self.tokenized=tokenized\n",
    "        self.max_length=max_length\n",
    "        self.jsonfile=\"multinli_1.0_train.jsonl\" if self.matched else \"multinli_1.0_dev_mismatched.jsonl\"\n",
    "        self.filename=os.path.join(self.root,self.jsonfile)\n",
    "\n",
    "\n",
    "        self.num_labels = 2\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.LABEL_MAP = {\n",
    "                \"entailment\": 0,\n",
    "                \"neutral\": 1,\n",
    "                \"contradiction\": 2,\n",
    "                \"hidden\": 0\n",
    "            }\n",
    "\n",
    "        self.data=[]\n",
    "        self.sentences=[]\n",
    "        self.labels=[]\n",
    "        self.load_data()\n",
    "        self.random_flip = torch.randint(392702, (200, ))\n",
    "#         self.random_flip = torch.randint(800, (20, ))\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.filename) as f:\n",
    "            for idx, line in enumerate(f):\n",
    "#                 if idx > 800:\n",
    "#                     continue\n",
    "                example=json.loads(line) # dict\n",
    "                self.data.append(example)\n",
    "        if self.tokenized:\n",
    "            self.tokenize()\n",
    "\n",
    "    \n",
    "    def tokenize(self):\n",
    "        for i, text in enumerate(self.data):\n",
    "            sent=text[\"sentence1\"]\n",
    "            label=text[\"gold_label\"]\n",
    "            if label not in self.LABEL_MAP:\n",
    "                continue\n",
    "\n",
    "            tokenized_text = self.tokenizer.tokenize(sent)\n",
    "            indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "            if len(indexed_tokens)<self.max_length:\n",
    "                indexed_tokens+=[0]*(self.max_length-len(indexed_tokens))\n",
    "            else:\n",
    "                indexed_tokens=indexed_tokens[:self.max_length]\n",
    "            indexed_tokens=np.array(indexed_tokens)\n",
    "\n",
    "            self.sentences.append(indexed_tokens)\n",
    "            self.labels.append(self.LABEL_MAP[label])\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sent = self.sentences[index]\n",
    "        if index in self.random_flip:\n",
    "            label = self.labels[index]+int(2*(torch.rand(1)>0.5)-1)\n",
    "            if label>2:\n",
    "                label = 0\n",
    "            elif label<0:\n",
    "                label = 2\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "\n",
    "        return index,sent,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "#         return 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "above-jamaica",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "# def Trainer(batch_size=4, epoch = 50, n_classes = 3, vocab_size = 30522):\n",
    "batch_size=4\n",
    "epoch = 50\n",
    "n_classes = 3\n",
    "vocab_size = 30522\n",
    "writer = SummaryWriter('runs/NLP_AUM_First')\n",
    "\n",
    "config = BertConfig(vocab_size)\n",
    "model = BertForSequenceClassification(config, n_classes)\n",
    "model.to(\"cuda\")\n",
    "dataset = MultiNLIDataset(\"./multinli_1.0\", max_length=217)\n",
    "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle=True)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = BertAdam(model.parameters(), lr = 0.000001)\n",
    "aum = torch.zeros([epoch, len(dataset), n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "simplified-mathematics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1456522166728973\n",
      "1.1209135419130325\n",
      "1.0955419850349426\n",
      "1.1125767797231674\n",
      "1.096754828095436\n",
      "1.0886997503042222\n",
      "1.0857273465394974\n",
      "1.0801356768608092\n",
      "1.0894037210941314\n",
      "1.0827822196483612\n",
      "1.0733021980524062\n",
      "1.0736334884166718\n",
      "1.065121978521347\n",
      "1.0574870485067367\n",
      "1.0595620465278626\n",
      "1.0459759545326233\n",
      "1.0344018590450288\n",
      "1.037968230843544\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-08addc6e071d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mrunning_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pointmask/lib/python3.6/site-packages/pytorch_pretrained_bert/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mupdate_with_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduled\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mupdate_with_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    logits_store = torch.zeros([len(dataset), n_classes]).cuda()\n",
    "    running_loss = 0.0\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        sample_idx, text_in, labels = batch\n",
    "        logits = model(text_in.cuda())\n",
    "\n",
    "        logits_store[sample_idx] = logits\n",
    "\n",
    "        loss = criterion(logits, labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        if idx % 100 == 99:\n",
    "            print(running_loss/100)\n",
    "            running_loss = 0.0\n",
    "    logits_topk, logits_topk_ind = torch.topk(logits_store, 2, 0)\n",
    "    aum[e] = logits_store - logits_topk[0][None]\n",
    "    aum[e, logits_topk_ind[0,0], 0] = logits_store[logits_topk_ind[0,0], 0] - logits_topk[1, 0]\n",
    "    aum[e, logits_topk_ind[0,1], 1] = logits_store[logits_topk_ind[0,1], 1] - logits_topk[1, 1]\n",
    "\n",
    "    attention_index = dataset.random_flip#Need the attention index to point out the flipped sample\n",
    "\n",
    "#     for ind in attention_index:\n",
    "#         writer.add_scalar(\"Sentence {}\".format(ind), aum[e, ind, dataset[ind][2]], e)\n",
    "    torch.save({aumaum, \"AUM.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "passing-compact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(logits_store - logits_topk[0][None]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "usual-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in dataset:\n",
    "    labels.append(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nervous-console",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unlike-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "aum = torch.zeros([epoch, len(dataset), n_classes])\n",
    "aum[e]=logits_store - logits_topk[0][None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "valuable-emphasis",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 760 is out of bounds for dimension 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0c0009acc6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogits_topk_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# - logits_topk[1, 0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 760 is out of bounds for dimension 0 with size 4"
     ]
    }
   ],
   "source": [
    "logits[logits_topk_ind[0,0], 0].shape\n",
    "# - logits_topk[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "close-circus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./multinli_1.0/multinli_1.0_train.jsonl' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"./multinli_1.0/multinli_1.0_train.jsonl\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        if idx>10:\n",
    "            continue\n",
    "        print(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointmask",
   "language": "python",
   "name": "pointmask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
